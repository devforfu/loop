{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from loop.callbacks import Callback, Order\n",
    "from loop.utils import calculate_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(sched):\n",
    "    xs = list(range(N))\n",
    "    ys = [sched(x) for x in xs]\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    ax.plot(xs, ys)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CosineAnnealing:\n",
    "    \"\"\"A schedule that returns eta multiplier in range from 0.0 to 1.0.\"\"\"\n",
    "    \n",
    "    def __init__(self, t_max, minmax=(0.0, 1.0), mult=2):\n",
    "        self.t_max = t_max\n",
    "        self.minmax = minmax\n",
    "        self.mult = mult\n",
    "        self.iter = 0\n",
    "        \n",
    "    def __call__(self, t):\n",
    "        self.iter += 1\n",
    "        (lo, hi), n = self.minmax, self.t_max\n",
    "        x = self.iter % n\n",
    "        eta = lo + (hi - lo)*(1 + np.cos(np.pi*x/n))/2\n",
    "        if x == 0:\n",
    "            self.iter = 0\n",
    "            self.t_max *= self.mult\n",
    "        return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(CosineAnnealing(t_max=N/2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def linear(epoch, t_max, minmax=(1e-7, 1)):\n",
    "    \"\"\"Simple linear schedule in minmax range.\"\"\"\n",
    "    lo, hi = minmax\n",
    "    k = (hi - lo)/(t_max - 1)\n",
    "    return k*epoch + lo\n",
    "\n",
    "\n",
    "def cosine(epoch, t_max, ampl=1.0):\n",
    "    \"\"\"Shifted and scaled cosine function.\"\"\"\n",
    "    t = epoch % t_max\n",
    "    return (1 + np.cos(np.pi*t/t_max))*ampl/2\n",
    "\n",
    "\n",
    "def inv_cosine(epoch, t_max, ampl=0.6):\n",
    "    \"\"\"A cosine function reflected on X-axis.\"\"\"\n",
    "    return 1 - cosine(epoch, t_max, ampl)\n",
    "\n",
    "\n",
    "def one_cycle(epoch, t_max, f1=inv_cosine, f2=cosine, pivot=0.3):\n",
    "    \"\"\"A combined schedule with two cosine half-waves.\"\"\"\n",
    "    pct = epoch / t_max\n",
    "    if pct < pivot:\n",
    "        return f1(epoch, pivot*t_max)\n",
    "    return f2(epoch - pivot*t_max, (1-pivot)*t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class Function:\n",
    "    def __init__(self, func, **params):\n",
    "        self.func = func\n",
    "        self.params = params\n",
    "    def __call__(self, t):\n",
    "        return self.func(t, **self.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "OneCycle = lambda **params: Function(one_cycle, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(OneCycle(t_max=N, pivot=0.3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(OneCycle(t_max=N, f1=partial(linear, minmax=(0.3, 1.0))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Scheduler(Callback):\n",
    "    \"\"\"Updates optimizer's learning rates using provided scheduling function.\"\"\"\n",
    "    \n",
    "    order = Order.Schedule()\n",
    "    \n",
    "    def __init__(self, opt, schedule: 'callable', params: list=None, mode: str='batch'):\n",
    "        assert mode in {'batch', 'epoch'}\n",
    "        params = _make_sched_params(params)\n",
    "        self.opt = opt\n",
    "        self.schedule = schedule\n",
    "        self.params = params\n",
    "        self.n_steps = 0\n",
    "        \n",
    "    def training_started(self, **kwargs):\n",
    "        self.history = defaultdict(list)\n",
    "        \n",
    "    def epoch_started(self, epoch, **kwargs):\n",
    "        if self.mode == 'epoch': \n",
    "            self.step(epoch)\n",
    "    \n",
    "    def batch_started(self, phase, **kwargs):\n",
    "        if self.mode == 'batch': \n",
    "            if phase.grad:\n",
    "                self.step(phase.batch_index)\n",
    "        \n",
    "    def step(self, t):\n",
    "        self.n_steps += 1\n",
    "        mult = self.schedule(t)\n",
    "        for i, group in enumerate(self.opt.param_groups):\n",
    "            for item in self.params:\n",
    "                name = item['name']\n",
    "                if name not in group:\n",
    "                    continue\n",
    "                start = opt.defaults[name]\n",
    "                inv = item.get('inverse', False)\n",
    "                d = (1 - mult) if inv else mult\n",
    "                absolute = item.get('absolute', False)\n",
    "                new_value = d if absolute else start * d\n",
    "                group[name] = new_value\n",
    "                self.history[name].append(new_value)\n",
    "                \n",
    "    def plot(self, params=None, axes=None):\n",
    "        params = params or ['lr']\n",
    "        records = {'iteration': list(range(self.n_steps))}\n",
    "        for conf in self.params:\n",
    "            name = conf['name']\n",
    "            if name in params:\n",
    "                records[name] = self.history[name]\n",
    "        df = pd.DataFrame(records)\n",
    "        if axes is None:\n",
    "            n = len(params)\n",
    "            f, axes = plt.subplots(*calculate_layout(n))\n",
    "        for i, param in enumerate(params):\n",
    "            df.plot(x='iteration', y=param, ax=axes.flat[i])\n",
    "        f.tight_layout()\n",
    "        return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_sched_params(params):\n",
    "    if params is None:\n",
    "        return [{'name': 'lr'}]\n",
    "    converted = []\n",
    "    for item in params:\n",
    "        if isinstance(item, str):\n",
    "            converted.append({'name': item})\n",
    "        elif isinstance(item, dict):\n",
    "            converted.append(item)\n",
    "        else:\n",
    "            raise TypeError(f'unexpected param type: {item}')\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    ([{'name': 'lr'}], [{'name': 'lr'}]),\n",
    "    (['lr', 'weight_decay'], [{'name': 'lr'}, {'name': 'weight_decay'}]),\n",
    "    (['lr', {'name': 'weight_decay'}], [{'name': 'lr'}, {'name': 'weight_decay'}])\n",
    "]\n",
    "for param, result in tests:\n",
    "    assert _make_sched_params(param) == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from loop.modules import TinyNet\n",
    "\n",
    "opt = optim.Adam(TinyNet().parameters(), lr=1.0, weight_decay=0.1)\n",
    "\n",
    "params = [\n",
    "    {'name': 'lr'},\n",
    "    {'name': 'weight_decay', 'inverse': True}\n",
    "]\n",
    "\n",
    "sched = Scheduler(opt, OneCycle(t_max=N, pivot=0.3), params)\n",
    "sched.training_started()\n",
    "\n",
    "for i in range(N):\n",
    "    sched.step(i)\n",
    "    \n",
    "sched.plot(['lr', 'weight_decay']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
