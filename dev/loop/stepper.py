# -----------------------------------------
# THIS FILE WAS AUTOGENERATED! DO NOT EDIT!
# -----------------------------------------
# file to edit: 03e_stepper.ipynb

from operator import itemgetter

from loop.callbacks import Callback, Order
from loop.modules import set_trainable, freeze_all
from loop.training import write_output


class GradualTraining(Callback):
    """Gradually un-freezes model layers.

    Helps to slowly 'warm-up' topmost layers before fine-tuning the first ones.

    Parameters:
        schedule: List of pairs (epoch, module) that describes when to enable
            for training specific layers of a model.
        start_frozen: If True, then all network layers are set frozen before
            the training loop is started.
        verbose: If True, the callback prints layer name after each un-freezing.

    """
    order = Order.Schedule(10)

    def __init__(self, steps: list, start_frozen: bool=True, verbose: bool=False):
        self.steps = sorted(steps, key=itemgetter(0))
        self.start_frozen = start_frozen
        self.verbose = verbose

    def training_started(self, **kwargs):
        if self.start_frozen:
            if self.verbose:
                write_output('Freezing all model layers\n')
            freeze_all(self.group.model)

    def epoch_started(self, epoch, **kwargs):
        for epoch_no, keys in self.steps:
            if isinstance(keys, str):
                keys = [keys]
            if epoch == epoch_no:
                set_trainable(self.group.model, keys)
                if self.verbose:
                    write_output(f'Un-freezing layer(s): {keys}\n')
                break
