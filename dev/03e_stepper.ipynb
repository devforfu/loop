{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from operator import itemgetter\n",
    "\n",
    "from loop.callbacks import Callback, Order\n",
    "from loop.modules import set_trainable, freeze_all\n",
    "from loop.training import write_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GradualTraining(Callback):\n",
    "    \"\"\"Gradually un-freezes model layers.\n",
    "    \n",
    "    Helps to slowly 'warm-up' topmost layers before fine-tuning the first ones.\n",
    "    \n",
    "    Parameters:\n",
    "        schedule: List of pairs (epoch, module) that describes when to enable\n",
    "            for training specific layers of a model.\n",
    "        start_frozen: If True, then all network layers are set frozen before \n",
    "            the training loop is started.\n",
    "        verbose: If True, the callback prints layer name after each un-freezing.\n",
    "\n",
    "    \"\"\"\n",
    "    order = Order.Schedule(10)\n",
    "    \n",
    "    def __init__(self, steps: list, start_frozen: bool=True, verbose: bool=False):\n",
    "        self.steps = sorted(steps, key=itemgetter(0))\n",
    "        self.start_frozen = start_frozen\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def training_started(self, **kwargs):\n",
    "        if self.start_frozen:\n",
    "            if self.verbose:\n",
    "                write_output('Freezing all model layers\\n')\n",
    "            freeze_all(self.group.model)\n",
    "        \n",
    "    def epoch_started(self, epoch, **kwargs):\n",
    "        for epoch_no, keys in self.steps:\n",
    "            if isinstance(keys, str):\n",
    "                keys = [keys]\n",
    "            if epoch == epoch_no:\n",
    "                set_trainable(self.group.model, keys)\n",
    "                if self.verbose:\n",
    "                    write_output(f'Un-freezing layer(s): {keys}\\n')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing all model layers\n",
      "Un-freezing layer(s): ['features.top']\n",
      "Epoch:    1 | train_loss=2.2104, valid_loss=2.1909\n",
      "Epoch:    2 | train_loss=2.0967, valid_loss=2.0835\n",
      "Un-freezing layer(s): ['features.block2.conv2']\n",
      "Epoch:    3 | train_loss=2.0564, valid_loss=2.0325\n",
      "Epoch:    4 | train_loss=2.0331, valid_loss=2.0114\n",
      "Un-freezing layer(s): ['features.block2']\n",
      "Epoch:    5 | train_loss=1.6722, valid_loss=1.5993\n",
      "Epoch:    6 | train_loss=1.2514, valid_loss=1.1457\n",
      "Un-freezing layer(s): ['features.block1']\n",
      "Epoch:    7 | train_loss=0.8768, valid_loss=0.7239\n",
      "Epoch:    8 | train_loss=0.5097, valid_loss=0.3482\n",
      "Epoch:    9 | train_loss=0.3720, valid_loss=0.2508\n",
      "Epoch:   10 | train_loss=0.2891, valid_loss=0.1749\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from loop.modules import fc_network, fc, Flatten\n",
    "from loop.training import Loop\n",
    "from loop.testing import get_mnist\n",
    "\n",
    "trn_ds, val_ds = get_mnist(flat=False)\n",
    "\n",
    "net = nn.Sequential(OrderedDict([\n",
    "    ('features', nn.Sequential(OrderedDict([\n",
    "        ('block1', nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(1, 10, 3)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(10, 32, 3)),\n",
    "            ('relu2', nn.ReLU())\n",
    "        ]))),\n",
    "        ('block2', nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(32, 32, 3)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(32, 32, 3))\n",
    "        ]))),\n",
    "        ('top', nn.Sequential(OrderedDict([\n",
    "            ('pool', nn.AdaptiveAvgPool2d(1)),\n",
    "            ('flat', Flatten()),\n",
    "            ('fc1', nn.Linear(32, 16)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(16, 10))\n",
    "        ])))\n",
    "    ])))\n",
    "]))\n",
    "\n",
    "steps = [\n",
    "    (1, 'features.top'),\n",
    "    (3, 'features.block2.conv2'),\n",
    "    (5, 'features.block2'),\n",
    "    (7, 'features.block1')\n",
    "]\n",
    "loop = Loop(net, cbs=[GradualTraining(steps, verbose=True)], loss_fn=cross_entropy)\n",
    "loop.fit_datasets(trn_ds, val_ds, epochs=10, batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
