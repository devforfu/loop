{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itertools import cycle\n",
    "import math\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    old_path\n",
    "except NameError:\n",
    "    old_path = sys.path.copy()\n",
    "    sys.path = [Path.cwd().parent.as_posix()] + old_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models\n",
    "from torchvision.datasets.folder import pil_loader, is_image_file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loop import train_classifier, make_phases\n",
    "from loop import callbacks as C\n",
    "from loop.schedule import CosineAnnealingSchedule\n",
    "from loop.config import defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_SIZE = 256, 256\n",
    "IMAGE_SIZE = 128\n",
    "CSV_PATH = Path.home()/'data'/'quick_draw'/'prepared'\n",
    "IMAGENET_STATS = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "COLORS = ['#0095EF', '#3C50B1', '#6A38B3', '#A224AD', '#F31D64', '#FE433C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleSchedule:\n",
    "    \n",
    "    def __init__(self, t, linear_pct=0.2, eta_max=1.0, eta_min=None, div_factor=100):\n",
    "        if eta_min is None:\n",
    "            eta_min = eta_max / div_factor\n",
    "        \n",
    "        self.t = t\n",
    "        self.linear_pct = linear_pct\n",
    "        self.eta_max = eta_max\n",
    "        self.eta_min = eta_min\n",
    "        \n",
    "        self.t_cosine = int(math.ceil(t*(1 - linear_pct))) + 1\n",
    "        self.t_linear = int(math.floor(t*linear_pct))\n",
    "        \n",
    "        self.cosine = CosineAnnealingSchedule(eta_min, eta_max, t_max=self.t_cosine, t_mult=1)\n",
    "        \n",
    "        self.linear = lambda x: x*(eta_max - eta_min)/self.t_linear + eta_min\n",
    "        \n",
    "        self.iter = 0\n",
    "    \n",
    "    def update(self, **kwargs):\n",
    "        self.iter += 1\n",
    "        if self.iter <= self.t_linear:\n",
    "            return self.linear(self.iter)\n",
    "        else:\n",
    "            return self.cosine.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schedule(schedule, n):\n",
    "    return [schedule.update() for _ in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_schedule(schedule, n=1000, **fig_kwargs):\n",
    "    xs, ys = zip(*list(enumerate(generate_schedule(schedule, n))))\n",
    "    f, ax = plt.subplots(1, 1, **fig_kwargs)\n",
    "    ax.plot(xs, ys, label='schedule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_schedule(OneCycleSchedule(1000, eta_max=1.0, linear_pct=0.2), n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRenderer:\n",
    "    \"\"\"Converts string with strokes into PIL image.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='b/w', bg='black', fg='white', lw: int=4,\n",
    "                 colors=None):\n",
    "\n",
    "        mode = mode if mode in ('b/w', 'rgb') else 'b/w'\n",
    "\n",
    "        self.render_fn = {\n",
    "            'b/w': render_bw,\n",
    "            'rgb': render_rgb\n",
    "        }[mode]\n",
    "\n",
    "        self.mode = mode\n",
    "        self.bg = bg\n",
    "        self.fg = fg\n",
    "        self.lw = lw\n",
    "        self.colors = cycle(colors or COLORS)\n",
    "\n",
    "    def render(self, strokes: str, image_size: tuple):\n",
    "        x_ref, y_ref = RAW_SIZE\n",
    "        x_max, y_max = image_size\n",
    "        ratio = x_max/float(x_ref), y_max/float(y_ref)\n",
    "        return self.render_fn(self, strokes, ratio, image_size)\n",
    "\n",
    "\n",
    "def render_bw(renderer, strokes, ratio, image_size):\n",
    "    bg, fg, lw = [getattr(renderer, x) for x in 'bg fg lw'.split()]\n",
    "\n",
    "    x_ratio, y_ratio = ratio\n",
    "    canvas = PIL.Image.new('RGB', image_size, color=bg)\n",
    "    draw = PIL.ImageDraw.Draw(canvas)\n",
    "\n",
    "    for segment in strokes.split('|'):\n",
    "        chunks = [int(x) for x in segment.split(',')]\n",
    "        while len(chunks) >= 4:\n",
    "            (x1, y1, x2, y2), chunks = chunks[:4], chunks[2:]\n",
    "            scaled = (\n",
    "                int(x1 * x_ratio), int(y1 * y_ratio),\n",
    "                int(x2 * x_ratio), int(y2 * y_ratio))\n",
    "            draw.line(tuple(scaled), fill=fg, width=lw)\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def render_rgb(renderer, strokes, ratio, image_size):\n",
    "    colors, bg, lw = [getattr(renderer, x) for x in 'colors bg lw'.split()]\n",
    "\n",
    "    x_ratio, y_ratio = ratio\n",
    "    canvas = PIL.Image.new('RGB', image_size, color=bg)\n",
    "    draw = PIL.ImageDraw.Draw(canvas)\n",
    "\n",
    "    for segment, color in zip(strokes.split('|'), colors):\n",
    "        chunks = [int(x) for x in segment.split(',')]\n",
    "        while len(chunks) >= 4:\n",
    "            (x1, y1, x2, y2), chunks = chunks[:4], chunks[2:]\n",
    "            scaled = (\n",
    "                int(x1 * x_ratio), int(y1 * y_ratio),\n",
    "                int(x2 * x_ratio), int(y2 * y_ratio))\n",
    "            draw.line(tuple(scaled), fill=color, width=lw)\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_renderer = ImageRenderer('rgb', bg='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doodles(Dataset):\n",
    "\n",
    "    def __init__(self, root: Path, train: bool=True,\n",
    "                 subset_size: int=None, image_size: int=RAW_SIZE,\n",
    "                 renderer=default_renderer, transforms=None):\n",
    "\n",
    "        subfolder = root/('train' if train else 'valid')\n",
    "        if isinstance(image_size, int):\n",
    "            image_size = image_size, image_size\n",
    "\n",
    "        worker = partial(read_category, subset_size)\n",
    "        with Pool(cpu_count()) as pool:\n",
    "            data = pool.map(worker, subfolder.glob('*.csv'))\n",
    "\n",
    "        merged = pd.concat(data)\n",
    "        targets = merged.word.values\n",
    "        classes = np.unique(targets)\n",
    "        class2idx = {v: k for k, v in enumerate(classes)}\n",
    "        labels = np.array([class2idx[c] for c in targets])\n",
    "\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.subset_size = subset_size\n",
    "        self.image_size = image_size\n",
    "        self.renderer = renderer\n",
    "        self.data = merged.drawing.values\n",
    "        self.classes = classes\n",
    "        self.class2idx = class2idx\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        strokes, target = self.data[item], self.labels[item]\n",
    "        img = self.renderer.render(strokes, self.image_size)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, target\n",
    "    \n",
    "    \n",
    "class TestImagesFolder(Dataset):\n",
    "\n",
    "    def __init__(self, path, image_size=RAW_SIZE,\n",
    "                 loader=pil_loader, pseudolabel=0):\n",
    "\n",
    "        path = Path(path)\n",
    "\n",
    "        if isinstance(image_size, int):\n",
    "            image_size = image_size, image_size\n",
    "\n",
    "        assert path.is_dir() and path.exists(), 'Not a directory!'\n",
    "        assert path.stat().st_size > 0, 'Directory is empty'\n",
    "\n",
    "        images = [file for file in path.iterdir() if is_image_file(str(file))]\n",
    "\n",
    "        self.path = path\n",
    "        self.image_size = image_size\n",
    "        self.loader = loader\n",
    "        self.images = images\n",
    "        self.pseudolabel = pseudolabel\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = self.loader(self.images[item])\n",
    "        img.thumbnail(self.image_size, PIL.Image.ANTIALIAS)\n",
    "        return img, self.pseudolabel\n",
    "    \n",
    "    \n",
    "def read_category(subset_size, path):\n",
    "    if subset_size is None:\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    for chunk in pd.read_csv(path, chunksize=min(10000, subset_size)):\n",
    "        data = data.append(chunk)\n",
    "        if len(data) >= subset_size:\n",
    "            break\n",
    "\n",
    "    return data[:subset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_model(model):\n",
    "    \"\"\"Converts model with nested modules into single list of modules\"\"\"\n",
    "    \n",
    "    def flatten(m):\n",
    "        children = list(m.children())\n",
    "        if not children:\n",
    "            return [m]\n",
    "        return sum([flatten(child) for child in children], [])\n",
    "    \n",
    "    return nn.Sequential(*flatten(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_sequential(model):\n",
    "    return nn.Sequential(*list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_shape(model):\n",
    "    \"\"\"Pass a dummy input through the sequential model to get the output tensor shape.\"\"\"\n",
    "    first, *rest = flat_model(model)\n",
    "    shape = first.in_channels, 128, 128\n",
    "    dummy_input = torch.zeros(shape)\n",
    "    out = model(dummy_input[None])\n",
    "    return list(out.size())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, size=1):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d(size)\n",
    "        self.max = nn.AdaptiveMaxPool2d(size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.max(x), self.avg(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    name = m.__class__.__name__\n",
    "    with torch.no_grad():\n",
    "        if name.find('Conv') != -1:\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif name.find('BatchNorm') != -1:\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 1e-3)\n",
    "        elif name.find('Linear') != -1:\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_linear(ni, no, dropout=None, bn=True):\n",
    "    layers = []\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm1d(ni))\n",
    "    if dropout is not None and dropout > 0:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    layers.append(nn.Linear(ni, no))\n",
    "    layers.append(nn.LeakyReLU(0.01, True))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, arch=models.resnet18, init_fn=init_weights):\n",
    "        super().__init__()\n",
    "        \n",
    "        model = arch(True)\n",
    "        seq_model = as_sequential(model)\n",
    "        backbone, classifier = seq_model[:-2], seq_model[-2:]\n",
    "        out_shape = get_output_shape(backbone)\n",
    "        input_size = out_shape[0] * 2\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.top = nn.Sequential(\n",
    "            AdaptiveConcatPool2d(),\n",
    "            Flatten(),\n",
    "            leaky_linear(input_size, 512, 0.25),\n",
    "            leaky_linear(512, 256, 0.5),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.init(init_fn)\n",
    "        \n",
    "    def freeze_backbone(self, freeze=True, bn=True):\n",
    "        for child in self.backbone.children():\n",
    "            name = child.__class__.__name__\n",
    "            if not bn and name.find('BatchNorm') != -1:\n",
    "                continue\n",
    "            for p in child.parameters():\n",
    "                p.requires_grad = not freeze\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.top(self.backbone(x))\n",
    "    \n",
    "    def init(self, fn=None):\n",
    "        if fn is None:\n",
    "            return\n",
    "        self.top.apply(fn)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 300\n",
    "image_size = 224\n",
    "n_train = 200\n",
    "n_valid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Doodles(\n",
    "    CSV_PATH, \n",
    "    train=True, \n",
    "    subset_size=n_train,\n",
    "    image_size=IMAGE_SIZE, \n",
    "    transforms=T.Compose([\n",
    "        T.Pad(4, padding_mode='reflect'),\n",
    "        T.Resize(image_size),\n",
    "        T.RandomAffine(degrees=5, \n",
    "                       translate=(0.1, 0.1), \n",
    "                       scale=(0.9, 1.1),\n",
    "                       fillcolor='white'),\n",
    "        T.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(*IMAGENET_STATS)\n",
    "    ])\n",
    ")\n",
    "\n",
    "valid_ds = Doodles(\n",
    "    CSV_PATH, \n",
    "    train=False,\n",
    "    subset_size=n_valid, \n",
    "    image_size=IMAGE_SIZE,\n",
    "    transforms=T.Compose([\n",
    "        T.Pad(4, padding_mode='reflect'),\n",
    "        T.Resize(image_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(*IMAGENET_STATS)\n",
    "    ])\n",
    ")\n",
    "\n",
    "cb = C.CallbacksGroup([\n",
    "    C.History(),\n",
    "    C.RollingLoss(),\n",
    "    C.StreamLogger(),\n",
    "    C.ProgressBar(),\n",
    "    C.Accuracy(),\n",
    "    C.Scheduler(\n",
    "        OneCycleSchedule(\n",
    "            t=len(train_ds),\n",
    "            linear_pct=0.2,\n",
    "            eta_max=1.0,\n",
    "            div_factor=100\n",
    "        ),\n",
    "        mode='batch'\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = make_phases(train_ds, valid_ds, batch_size)\n",
    "model = Classifier(340, arch=models.resnet50)\n",
    "model.freeze_backbone()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "train_classifier(model, opt, phases, cb, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
