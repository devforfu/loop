{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models on Classical Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the classes and utils from the `loop` package are used to train simple models on various \"classical\" computer vision datasets. It is intended to be used as a benchmark showing the quality of the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    old_path\n",
    "except NameError:\n",
    "    old_path = sys.path.copy()\n",
    "    sys.path = [Path.cwd().parent.as_posix()] + old_path\n",
    "    \n",
    "warnings.simplefilter('ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torchvision.models import resnet18, resnet34\n",
    "\n",
    "from loop import find_lr, train, train_classifier, make_phases\n",
    "from loop import callbacks as C\n",
    "from loop import plot\n",
    "from loop.config import defaults\n",
    "from loop.optimizers.adamw import AdamW\n",
    "from loop.schedule import OneCycleSchedule\n",
    "from loop.torch_helpers.modules import tiny_classifier, FineTunedModel\n",
    "from loop.torch_helpers.utils import freeze_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_path(name, root=Path('~/data')):\n",
    "    return root.expanduser()/name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cuda:1')\n",
    "mnist_stats = ([0.15]*3, [0.15]*3)\n",
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "The very first benchmark is running the training loop against ubiquitious MNIST dataset. Here is a [leaderboard](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html) with the best results on this dataset. The first entries look like this:\n",
    "\n",
    "|Error|Method|Venue|\n",
    "|-----|------|-----|\n",
    "|0.21%|Regularization of Neural Networks using DropConnect|ICML 2013|\n",
    "|0.23%|Multi-column Deep Neural Networks for Image Classiï¬cation|CVPR 2012|\n",
    "|0.23%|APAC: Augmented PAttern Classification with Neural Networks|arXiv 2015|\n",
    "|0.24%|Batch-normalized Maxout Network in Network|arXiv 2015|\n",
    "\n",
    "In other words, the best results nowadays are around `99.7%` of accuracy. Let's see if we can get close to these values.\n",
    "\n",
    "We're going to use `torchvision` package to simplify data loading and preparation process. Next, we create the training phases to track metrics and wrap datasets into data loaders. Finally, we create a list of callbacks and initialize the optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = data_path('mnist')\n",
    "\n",
    "train_ds = MNIST(\n",
    "    root, train=True, download=True,\n",
    "    transform=T.Compose([T.Resize(32),\n",
    "                         T.RandomAffine(5, translate=(0.05, 0.05), scale=(0.9, 1.2)),\n",
    "                         T.ToTensor(), \n",
    "                         T.Normalize(*mnist_stats)]))\n",
    "\n",
    "valid_ds = MNIST(\n",
    "    root, train=False, download=True,\n",
    "    transform=T.Compose([T.Resize(32),\n",
    "                         T.ToTensor(), \n",
    "                         T.Normalize(*mnist_stats)]))\n",
    "\n",
    "phases = make_phases(train_ds, valid_ds, batch_size=1024, num_workers=(12, 4))\n",
    "\n",
    "cb = C.CallbacksGroup([\n",
    "    C.Accuracy(),\n",
    "    C.RollingLoss(),\n",
    "    C.History(),\n",
    "    C.MemoryUsage(),\n",
    "    C.StreamLogger(),\n",
    "    C.ProgressBar(),\n",
    "    C.Scheduler(\n",
    "        OneCycleSchedule(\n",
    "            t=len(phases[0].loader) * 3,\n",
    "            linear_pct=0.3,\n",
    "            eta_max=1.0,\n",
    "            div_factor=25\n",
    "        ),\n",
    "        mode='batch',\n",
    "        params_conf=[\n",
    "            {'name': 'lr'},\n",
    "            {'name': 'weight_decay', 'inverse': True}\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "\n",
    "model = tiny_classifier(n_channels=1, n_out=10)\n",
    "opt = AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11053ff649e498289f730c722914888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=59), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d66c1fc96647118d5781fe22668bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 | train_loss=0.9978, train_accuracy=0.6029, valid_loss=0.1254, valid_accuracy=0.9617\n",
      "Epoch:    2 | train_loss=0.5518, train_accuracy=0.8689, valid_loss=0.0949, valid_accuracy=0.9788\n",
      "Epoch:    3 | train_loss=0.4207, train_accuracy=0.8946, valid_loss=0.1034, valid_accuracy=0.9765\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, opt, phases, cb, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting more then `97%` of accuracy after training 3 epochs only, training the network from scratch and using very simple architecture. Therefore, we could suppose that our training loop works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST: Pretrained and Augmented\n",
    "\n",
    "Could we improve our results with a pretrained model and with applying some data augmentation techniques? Let's make a try and see. \n",
    "\n",
    "But first of all, we need to make our samples ready to pass into the pretrained model. Most of the pretrained networks are trained on the ImageNet dataset which consists of colored images, i.e., the images with 3 channels at first dimention. However, the MNIST dataset contains grayscale images with single channel. To make it compatible with the models we're going to try, we need to  convert these 1-channel images into 3-channel images. The most straightforward way to do so is to duplicate the original channel three times. The `ExpandChannels` class does exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandChannels:\n",
    "    \n",
    "    def __init__(self, num_of_channels=3):\n",
    "        self.nc = num_of_channels\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return x.expand((self.nc,) + x.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, this time we don't create the callbacks explicitly but using a convenience `train_classifier` function that adds required callbacks for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "\n",
    "train_ds = MNIST(\n",
    "    root, train=True, download=True,\n",
    "    transform=T.Compose([T.Resize(image_size),\n",
    "                         T.Pad(4, padding_mode='reflect'),\n",
    "                         T.RandomAffine(5, translate=(0.05, 0.05), scale=(0.9, 1.2)),\n",
    "                         T.RandomResizedCrop(image_size, scale=(0.8, 1.2)),\n",
    "                         T.ToTensor(), \n",
    "                         ExpandChannels(3),\n",
    "                         T.Normalize(*imagenet_stats)]))\n",
    "\n",
    "valid_ds = MNIST(\n",
    "    root, train=False, download=True,\n",
    "    transform=T.Compose([T.Resize(image_size),\n",
    "                         T.ToTensor(), \n",
    "                         ExpandChannels(3),\n",
    "                         T.Normalize(*imagenet_stats)]))\n",
    "\n",
    "model = FineTunedModel(n_out=10, arch=resnet18)\n",
    "opt = AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that by default, the fine-tuned model \"freezes\" backbone layers, and trains custom top layers only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers status\n",
      "--------------------------------------------------------------------------------\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "MaxPool2d                                                               [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "ReLU                                                                    [-     ]\n",
      "Conv2d                                                                  [frozen]\n",
      "BatchNorm2d                                                             [frozen]\n",
      "AdaptiveAvgPool2d                                                       [-     ]\n",
      "AdaptiveMaxPool2d                                                       [-     ]\n",
      "Flatten                                                                 [-     ]\n",
      "BatchNorm1d                                                             [ok    ]\n",
      "Linear                                                                  [ok    ]\n",
      "Dropout                                                                 [-     ]\n",
      "LeakyReLU                                                               [-     ]\n",
      "BatchNorm1d                                                             [ok    ]\n",
      "Linear                                                                  [ok    ]\n",
      "Dropout                                                                 [-     ]\n",
      "LeakyReLU                                                               [-     ]\n",
      "Linear                                                                  [ok    ]\n"
     ]
    }
   ],
   "source": [
    "freeze_status(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we also change a scheduling function from cosine annealing to one-cycle policy to see if we could also get a better result with a different scheduling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5160ea73524a4fa117aafcaef315ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=118), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd09b87855514514a25fd62f89f42d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 | train_loss=0.4205, train_accuracy=0.8464, valid_loss=0.3566, valid_accuracy=0.9334\n",
      "Epoch:    2 | train_loss=0.3206, train_accuracy=0.8944, valid_loss=0.2490, valid_accuracy=0.9440\n",
      "Epoch:    3 | train_loss=0.2961, train_accuracy=0.9215, valid_loss=0.2726, valid_accuracy=0.9480\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = train_classifier(model, opt, (train_ds, valid_ds), \n",
    "                           epochs=3, batch_size=512,\n",
    "                           schedule_params={\n",
    "                               'schedule': 'cos_anneal', \n",
    "                               'schedule_config': {'eta_min': 0.1}},\n",
    "                           num_workers=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are promising but not as good as our simplistic model. Let's see what can we get if unfreeze the backbone layers and train the model with differential learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results['callbacks']['scheduler'].parameter_history('lr', 'weight_decay')).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'frozen.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('frozen.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_backbone(False)\n",
    "opt = AdamW([\n",
    "    {'params': model.backbone.parameters(), 'lr': 1e-4, 'weigth_decay': 1e-5},\n",
    "    {'params': model.top.parameters(), 'lr': 1e-3, 'weigth_decay': 1e-3}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c801d08c44f4a17b9a4cc3fb2af0132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=118), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3320336ffd5e454abe3d284b9721dea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 | train_loss=0.0541, train_accuracy=0.9795, valid_loss=0.0212, valid_accuracy=0.9931\n",
      "Epoch:    2 | train_loss=0.0303, train_accuracy=0.9906, valid_loss=0.0262, valid_accuracy=0.9901\n",
      "Epoch:    3 | train_loss=0.0253, train_accuracy=0.9931, valid_loss=0.0226, valid_accuracy=0.9932\n",
      "Epoch:    4 | train_loss=0.0186, train_accuracy=0.9949, valid_loss=0.0196, valid_accuracy=0.9952\n",
      "Epoch:    5 | train_loss=0.0155, train_accuracy=0.9956, valid_loss=0.0184, valid_accuracy=0.9942\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = train_classifier(model, opt, (train_ds, valid_ds), \n",
    "                           epochs=5, batch_size=512,\n",
    "                           schedule_params={'schedule': 'one_cycle'},\n",
    "                           num_workers=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting even closer the top entries of the scoreboard! It seems that our training loop and schedulers are going in a right direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10\n",
    "\n",
    "The CIFAR10 dataset is a more challenging task. Though modern deep learning architectures are capable to show quite good results even in this case. Therefore, it is also a good candidate to check how well performs the written code.\n",
    "\n",
    "The process is the same as for MNIST:\n",
    "\n",
    "1. Create datasets and data loaders\n",
    "2. Initialize optimizer and schedulers\n",
    "3. Start the training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = data_path('cifar10')\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "train_ds = CIFAR10(\n",
    "    root, train=True, download=True,\n",
    "    transform=T.Compose([T.Resize(image_size),\n",
    "                         T.Pad(8, padding_mode='reflect'),\n",
    "                         T.RandomAffine(5, translate=(0.05, 0.05), scale=(0.8, 1.2)),\n",
    "                         T.RandomResizedCrop(image_size, scale=(0.8, 1.1)),\n",
    "                         T.RandomHorizontalFlip(),\n",
    "                         T.ToTensor(), \n",
    "                         T.Normalize(*imagenet_stats)]))\n",
    "\n",
    "valid_ds = CIFAR10(\n",
    "    root, train=False, download=True,\n",
    "    transform=T.Compose([T.Resize(image_size),\n",
    "                         T.ToTensor(), \n",
    "                         T.Normalize(*imagenet_stats)]))\n",
    "\n",
    "model = FineTunedModel(n_out=10, arch=resnet34)\n",
    "opt = AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a385a6247a7345d9b9385818dc5836e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='lr_finder', max=49), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs, losses = find_lr(model, opt, train_ds, batch_size=1024, loss_fn=F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/ck/code/loop/loop/plot/learning_rate.py(14)lr_loss_curve()\n",
      "-> min_lr, max_lr = zoom\n",
      "(Pdb) zoom\n",
      "(1e-07, 0.01)\n",
      "(Pdb) n\n",
      "> /home/ck/code/loop/loop/plot/learning_rate.py(15)lr_loss_curve()\n",
      "-> lrs, losses = zip(*[(x, y) for x, y in zip(lrs, losses) if min_lr <= x <= max_lr])\n",
      "(Pdb) lrs\n",
      "[1e-07, 0.02083343125, 0.041666762499999996, 0.06250009375, 0.083333425, 0.10416675625, 0.1250000875, 0.14583341875, 0.16666675, 0.18750008125, 0.2083334125, 0.22916674375, 0.250000075, 0.27083340624999996, 0.29166673749999994, 0.3125000687499999, 0.3333333999999999, 0.35416673124999987, 0.37500006249999984, 0.3958333937499998, 0.4166667249999998, 0.43750005624999977, 0.45833338749999974, 0.4791667187499997, 0.5000000499999997, 0.5208333812499997, 0.5416667124999996, 0.5625000437499996, 0.5833333749999996, 0.6041667062499996, 0.6250000374999996, 0.6458333687499995, 0.6666666999999995, 0.6875000312499995, 0.7083333624999995, 0.7291666937499994, 0.7500000249999994, 0.7708333562499994, 0.7916666874999994, 0.8125000187499993, 0.8333333499999993, 0.8541666812499993, 0.8750000124999993, 0.8958333437499992, 0.9166666749999992, 0.9375000062499992, 0.9583333374999992, 0.9791666687499991, 0.9999999999999991]\n"
     ]
    }
   ],
   "source": [
    "plot.lr_loss_curve(lrs, losses, zoom=(1e-7, 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439c9c95c33a48ea97b4aaaade56b1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9620ee13b24d809373af21d88308d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 | train_loss=0.9926, train_accuracy=0.6384, valid_loss=0.8086, valid_accuracy=0.7701\n",
      "Epoch:    2 | train_loss=0.8926, train_accuracy=0.7034, valid_loss=0.7647, valid_accuracy=0.7501\n",
      "Epoch:    3 | train_loss=0.8665, train_accuracy=0.7110, valid_loss=0.7338, valid_accuracy=0.7580\n",
      "Epoch:    4 | train_loss=0.8440, train_accuracy=0.7149, valid_loss=0.7053, valid_accuracy=0.7795\n",
      "Epoch:    5 | train_loss=0.8387, train_accuracy=0.7183, valid_loss=0.7036, valid_accuracy=0.7830\n",
      "Epoch:    6 | train_loss=0.8407, train_accuracy=0.7171, valid_loss=0.7718, valid_accuracy=0.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Image.__del__ at 0x7f25ed365378>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ck/anaconda3/envs/fastai/lib/python3.7/site-packages/PIL/Image.py\", line 601, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-307b38e4e09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0;34m'schedule'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'one_cycle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                'schedule_config': {'eta_min': 0.1}},\n\u001b[0;32m----> 6\u001b[0;31m                            num_workers=(12, 4))\n\u001b[0m",
      "\u001b[0;32m~/code/loop/loop/training/training.py\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, opt, data, epochs, batch_size, callbacks, num_workers, device, schedule_params)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mschedule_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mcallbacks_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallbacksGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'phases'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'device'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/loop/loop/training/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, phases, callbacks_group, epochs, device, loss_fn)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mphase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = train_classifier(model, opt, (train_ds, valid_ds), \n",
    "                           epochs=10, batch_size=512,\n",
    "                           schedule_params={\n",
    "                               'schedule': 'one_cycle', \n",
    "                               'schedule_config': {'eta_min': 0.1}},\n",
    "                           num_workers=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
